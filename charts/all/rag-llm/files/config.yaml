llm_providers:
  - name: "OpenShift AI (vLLM)"
    enabled: True
    models:
      - name: {{ (split "/" .Values.global.model.vllm)._1 }}
        weight: 1
        enabled: True
        url: {{ printf "https://vllm-inference-service-predictor-%s.%s/v1" .Release.Namespace .Values.global.localClusterDomain }}
        params:
          - name: max_new_tokens
            value: 1024
          - name: temperature
            value: 0.01
          - name: top_k
            value: 10
          - name: top_p
            value: 0.95
          - name: repetition_penalty
            value: 1.03
          - name: verbose
            value: False
          - name: typical_p
            value: 0.95
default_provider: "OpenShift AI (vLLM)"
default_model: {{ .Values.global.model.vllm }}
# type values=(default, round_robin,  all)
type: all
